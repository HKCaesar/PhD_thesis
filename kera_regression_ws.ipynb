{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 101\n",
      "Trainable params: 101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "44/44 [==============================] - 1s 18ms/step - loss: 22.5583 - mean_absolute_error: 2.9042 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 0s 549us/step - loss: 19.1675 - mean_absolute_error: 2.2770 - acc: 0.0000e+00\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 0s 555us/step - loss: 18.3765 - mean_absolute_error: 1.8766 - acc: 0.0000e+00\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 0s 502us/step - loss: 18.1753 - mean_absolute_error: 1.6946 - acc: 0.0000e+00\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 0s 738us/step - loss: 18.0962 - mean_absolute_error: 1.6475 - acc: 0.0000e+00\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 0s 904us/step - loss: 18.0495 - mean_absolute_error: 1.6961 - acc: 0.0000e+00\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 0s 734us/step - loss: 18.0098 - mean_absolute_error: 1.7348 - acc: 0.0000e+00\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 0s 699us/step - loss: 17.9583 - mean_absolute_error: 1.7289 - acc: 0.0000e+00\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 0s 609us/step - loss: 17.9543 - mean_absolute_error: 1.7096 - acc: 0.0000e+00\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 17.9139 - mean_absolute_error: 1.6645 - acc: 0.0000e+00\n",
      "1.5699635\n",
      "Root Mean squared error: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel=wider_model()\\npred= model.predict(x_test)\\nprint(\"Root Mean squared error: %.2f\"\\n      % math.sqrt( mean_squared_error(y_test, pred)))\\nplt.figure()\\nplt.scatter(x_test[:,:1].flatten(), y_test, c=\"k\", label=\"test samples\")\\nplt.plot(x_test[:,:1].flatten(), pred, c=\"g\", label=\"estimate line\", linewidth=2)\\nplt.xlabel(\"data\")\\nplt.ylabel(\"target\")\\nplt.title(\"the SAR_Regression\")\\nplt.legend()\\nplt.show()\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "X = np.load(\"X.npy\")\n",
    "Y = np.load(\"y.npy\")\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(3, input_dim=3, kernel_initializer='normal', activation='relu'))\n",
    "\tmodel.add(Dense(1, kernel_initializer='normal'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "'''\n",
    "numpy.random.seed(seed)\n",
    "# evaluate model with standardized dataset\n",
    "estimator = KerasRegressor(build_fn=baseline_model, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) RMSE\" % (results.mean(), results.std()))\n",
    "'''\n",
    "'''\n",
    "numpy.random.seed(seed)\n",
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasRegressor(build_fn=baseline_model, epochs=50, batch_size=5, verbose=0)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = KFold(n_splits=10, random_state=seed)\n",
    "results = cross_val_score(pipeline, X, Y, cv=kfold)\n",
    "\n",
    "print(\"Standardized: %.2f (%.2f) RMSE\" % (results.mean(), results.std()))\n",
    "\n",
    "print(results.shape)\n",
    "'''\n",
    "def build_baseline_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=3, input_dim=3))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "    regressor.summary()\n",
    "    \n",
    "    return regressor\n",
    "def build_larger_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=16, input_dim=3))\n",
    "    regressor.add(Dense(units=8))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "    regressor.summary()\n",
    "    return regressor\n",
    "def build_wider_regressor():\n",
    "    regressor = Sequential()\n",
    "    regressor.add(Dense(units=20, input_dim=3, activation='relu'))\n",
    "    regressor.add(Dense(units=1))\n",
    "    regressor.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae','accuracy'])\n",
    "    regressor.summary()\n",
    "    \n",
    "    return regressor\n",
    "# define the model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.3,random_state=7)\n",
    "data=np.load(\"data.npz\")\n",
    "x_train=data['x_train']\n",
    "y_train=data['y_train']\n",
    "y_test=data['y_test']\n",
    "y_test=data['y_test']\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "regressor = KerasRegressor(build_fn=build_wider_regressor, batch_size=4,epochs=10)\n",
    "results=regressor.fit(x_train,y_train)\n",
    "results.model.save('saved_wider_model.h5')\n",
    "y_pred= regressor.predict(x_test)\n",
    "#y_test=Y\n",
    "print np.max(y_pred)\n",
    "print(\"Root Mean squared error: %.2f\"\n",
    "      % math.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "'''\n",
    "model=wider_model()\n",
    "pred= model.predict(x_test)\n",
    "print(\"Root Mean squared error: %.2f\"\n",
    "      % math.sqrt( mean_squared_error(y_test, pred)))\n",
    "plt.figure()\n",
    "plt.scatter(x_test[:,:1].flatten(), y_test, c=\"k\", label=\"test samples\")\n",
    "plt.plot(x_test[:,:1].flatten(), pred, c=\"g\", label=\"estimate line\", linewidth=2)\n",
    "plt.xlabel(\"data\")\n",
    "plt.ylabel(\"target\")\n",
    "plt.title(\"the SAR_Regression\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_dl_model is ok\n",
      "2.776842200999831\n",
      "wider_dl_model is ok\n",
      "0.7436874050235834\n",
      "larger_dl_model is ok\n",
      "1.5318170771285788\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "baseline_model=load_model('saved_baseline_model.h5')\n",
    "\n",
    "data=np.load('data.npz')\n",
    "x_test=data['x_test']\n",
    "y_test=data['y_test']\n",
    "base_predict = baseline_model.predict(x_test)\n",
    "np.save(\"base_dl_pred.npy\",base_predict)\n",
    "print (\"base_dl_model is ok\")\n",
    "base_dl_predict=np.load(\"base_dl_pred.npy\")\n",
    "base_dl_rmse=np.sqrt(mean_squared_error(y_test,base_dl_predict))\n",
    "print(base_dl_rmse) \n",
    "\n",
    "wider_model=load_model('saved_wider_model.h5')\n",
    "wider = wider_model.predict(x_test)\n",
    "np.save(\"wider_dl_pred.npy\",wider)\n",
    "print (\"wider_dl_model is ok\")\n",
    "wider_dl_predict=np.load(\"wider_dl_pred.npy\")\n",
    "wider_dl_rmse=np.sqrt(mean_squared_error(y_test,wider_dl_predict))\n",
    "print(wider_dl_rmse) \n",
    "\n",
    "larger_model=load_model('saved_larger_model.h5')\n",
    "larger = larger_model.predict(x_test)\n",
    "np.save(\"larger_dl_pred.npy\",larger)\n",
    "print (\"larger_dl_model is ok\")\n",
    "larger_dl_predict=np.load(\"larger_dl_pred.npy\")\n",
    "larger_dl_rmse=np.sqrt(mean_squared_error(y_test,larger_dl_predict))\n",
    "print(larger_dl_rmse) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
